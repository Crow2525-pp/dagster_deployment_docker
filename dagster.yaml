scheduler:
  module: dagster.core.scheduler
  class: DagsterDaemonScheduler

run_coordinator:
  module: dagster.core.run_coordinator
  class: QueuedRunCoordinator


run_launcher:
  module: dagster_aws.ecs
  class: EcsRunLauncher
  config:
    secrets:
      - name: "AWS_ACCESS_KEY_ID"
        valueFrom: "arn:aws:secretsmanager:eu-central-1:12312321:secret:aws_credentials-12312321:AWS_ACCESS_KEY_ID::"
      - name: "AWS_SECRET_ACCESS_KEY"
        valueFrom: "arn:aws:secretsmanager:eu-central-1:12312321:secret:aws_credentials-12312321:AWS_SECRET_ACCESS_KEY::"
    env_vars:
      - DAGSTER_POSTGRES_HOSTNAME
      - DAGSTER_POSTGRES_USER
      - DAGSTER_POSTGRES_PASSWORD
      - DAGSTER_POSTGRES_DB
      - DATABASE_IP
      - DATABASE_PORT
      - DATABASE_USER
      - DATABASE_PASSWORD
      - DATABASE_NAME
    run_resources:
      cpu: "256"
      memory: "512" # In MiB

storage:
  postgres:
    postgres_db:
      hostname:
        env: DAGSTER_POSTGRES_HOSTNAME
      username:
        env: DAGSTER_POSTGRES_USER
      password:
        env: DAGSTER_POSTGRES_PASSWORD
      db_name:
        env: DAGSTER_POSTGRES_DB
      port: 5432


compute_logs:
  module: dagster_aws.s3.compute_log_manager
  class: S3ComputeLogManager
  config:
    bucket: "etl-dagster-data"
    prefix: "compute-logs"
    skip_empty_files: true
    upload_interval: 30

